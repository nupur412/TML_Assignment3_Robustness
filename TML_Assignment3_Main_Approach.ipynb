{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook trains a robust classifier against adversarial examples and implements an approach that achieves the highest accuracy for clean, as well as adversarial examples created using FGSM and PGD based on [Assignment 3](https://github.com/sprintml/tml_2024/blob/main/Assignment3.pdf) of course on Trustworthy Machine Learning offered during Summer Semester 2024."
      ],
      "metadata": {
        "id": "bypDsefK_XU6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6Hme9C3E4bm"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import torch\n",
        "import torchvision\n",
        "import os\n",
        "import json\n",
        "import io\n",
        "import sys\n",
        "import base64\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pickle\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torch.utils.data import Dataset\n",
        "from torch.autograd import Variable\n",
        "from typing import Tuple\n",
        "from torchvision.models import resnet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RU5x2DvNIz2",
        "outputId": "76d170b3-e736-4263-b413-12e0ae2300f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xm4NfdKNNU0"
      },
      "outputs": [],
      "source": [
        "os.chdir(\"/content/drive/MyDrive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDethSapFaJN"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SL5sdGfALvIb",
        "outputId": "7c126b68-e43e-4659-ecfa-49323b0a5679"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cwd:  /content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "cwd = os.getcwd()\n",
        "print('cwd: ', cwd)\n",
        "\n",
        "class TaskDataset(Dataset):\n",
        "    def __init__(self, transform=None):\n",
        "\n",
        "        self.ids = []\n",
        "        self.imgs = []\n",
        "        self.labels = []\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index) -> Tuple[int, torch.Tensor, int]:\n",
        "        id_ = self.ids[index]\n",
        "        img = self.imgs[index]\n",
        "        if not self.transform is None:\n",
        "            img = self.transform(img)\n",
        "        label = self.labels[index]\n",
        "        return id_, img, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the dataset and applying transformation"
      ],
      "metadata": {
        "id": "GU7DGVsAEISZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKNNCWgWNaJF"
      },
      "outputs": [],
      "source": [
        "data: TaskDataset = torch.load(\"./Train.pt\", map_location=\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFlfSN7CFyCa"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.Lambda(lambda x: x.convert(\"RGB\")),\n",
        "        transforms.ToTensor(),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Dg9kihMF6sj"
      },
      "outputs": [],
      "source": [
        "data.transform = transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rKd6f_73AsA"
      },
      "outputs": [],
      "source": [
        "# The length of the provided dataset is 100000, so we split it into train and validation datasets\n",
        "train_size = 90000\n",
        "val_size = 10000\n",
        "\n",
        "train_dataset, val_dataset = random_split(data, [train_size, val_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJN6wvqsGxV6"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We make use of ensemble method and create four instances of Resnet50 model in order to create a more robust model. The intuition behind this is that, an adversarial example that fools one model might not always fool the other one. Thus, combining the predictions of all three trained models can help in better generalization."
      ],
      "metadata": {
        "id": "5b93I3zlevJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = torchvision.models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "model1.fc = nn.Linear(model1.fc.in_features, 10)\n",
        "model1 = model1.to(device)\n",
        "\n",
        "model2 = torchvision.models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "model2.fc = nn.Linear(model2.fc.in_features, 10)\n",
        "model2 = model2.to(device)\n",
        "\n",
        "model3 = torchvision.models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "model3.fc = nn.Linear(model3.fc.in_features, 10)\n",
        "model3 = model3.to(device)\n",
        "\n",
        "model4 = torchvision.models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "model4.fc = nn.Linear(model4.fc.in_features, 10)\n",
        "model4 = model4.to(device)\n",
        "\n",
        "ensemble_model_set = [model1, model2, model3, model4]"
      ],
      "metadata": {
        "id": "Pr1ludwUYbbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_model1 = optim.SGD(model1.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
        "optimizer_model2 = optim.SGD(model2.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
        "optimizer_model3 = optim.SGD(model3.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
        "optimizer_model4 = optim.SGD(model4.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)"
      ],
      "metadata": {
        "id": "vf22mO19Yln7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following block, we define a student model. our idea is to transfer(distill) the knowledge of the ensemble models into the student model. By doing this, we also make the student model more robust."
      ],
      "metadata": {
        "id": "-tAjxt3GgIVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "student_model = torchvision.models.resnet50(weights=None)\n",
        "student_model.fc = nn.Linear(student_model.fc.in_features, 10)\n",
        "student_model = student_model.to(device)\n",
        "\n",
        "optimizer_student_model = optim.SGD(student_model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "lGQSy5H1biLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following block, FGSM and PGD attacks are defined"
      ],
      "metadata": {
        "id": "UINZzRWdhJQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fgsm_attack(model, images, labels, epsilon):\n",
        "    images = images.clone().detach().to(device)\n",
        "    labels = labels.clone().detach().to(device)\n",
        "    images.requires_grad = True\n",
        "    outputs = model(images)\n",
        "    loss = nn.CrossEntropyLoss()(outputs, labels)\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "    data_grad = images.grad.data\n",
        "    perturbed_image = images + epsilon * data_grad.sign()\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    return perturbed_image"
      ],
      "metadata": {
        "id": "B5qPIaqwbzXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pgd_attack(model, images, labels, epsilon=0.031, alpha=0.007, iters=5):\n",
        "    images = images.clone().detach().to(device)\n",
        "    labels = labels.clone().detach().to(device)\n",
        "    original_images = images.clone().detach()\n",
        "    for i in range(iters):\n",
        "        images.requires_grad = True\n",
        "        outputs = model(images)\n",
        "        model.zero_grad()\n",
        "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
        "        loss.backward()\n",
        "        adv_images = images + alpha * images.grad.sign()\n",
        "        eta = torch.clamp(adv_images - original_images, min=-epsilon, max=epsilon)\n",
        "        images = torch.clamp(original_images + eta, min=0, max=1).detach_()\n",
        "    return images"
      ],
      "metadata": {
        "id": "TQDV5nEyb0cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following distillation loss function combines the cross entropy loss with KL divergence based distillation loss."
      ],
      "metadata": {
        "id": "dl_wxy_ni7S9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def distillation_loss(output, labels, teacher_outputs, T, alpha):\n",
        "    loss = nn.KLDivLoss()(F.log_softmax(output / T, dim=1), F.softmax(teacher_outputs / T, dim=1)) * (alpha * T * T) + \\\n",
        "           F.cross_entropy(output, labels) * (1. - alpha)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "vkdE6Yj5b6Tb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "epsilon = 0.050\n",
        "alpha = 0.007\n",
        "pgd_iters = 5\n",
        "T = 2.0\n",
        "alpha_distillation = 0.7"
      ],
      "metadata": {
        "id": "Nw5oOlXvb-cO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following block does the ensemble training, obtains the ensemble outputs for clean as well as adversarial images generated by applying FGSM and PGD attacks, then calculates the distillation loss for all three sets of images (clean, FGSM and PGD), combines the obtained losses and finally saves the trained student model."
      ],
      "metadata": {
        "id": "dp0CNYiZjNdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    for model, optimizer in zip(ensemble_model_set, [optimizer_model1, optimizer_model2, optimizer_model3, optimizer_model4]):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for batch_idx, (ids, images, labels) in enumerate(train_loader):\n",
        "          images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "          # Generating adversarial examples by FGSM and PGD attacks\n",
        "          fgsm_images = fgsm_attack(student_model, images, labels, epsilon)\n",
        "          pgd_images = pgd_attack(student_model, images, labels, epsilon, alpha, pgd_iters)\n",
        "\n",
        "          optimizer_student_model.zero_grad()\n",
        "\n",
        "          # Get ensemble outputs\n",
        "          with torch.no_grad():\n",
        "              ensemble_outputs = sum([model(images) for model in ensemble_model_set]) / len(ensemble_model_set)\n",
        "              ensemble_outputs_fgsm = sum([model(fgsm_images) for model in ensemble_model_set]) / len(ensemble_model_set)\n",
        "              ensemble_outputs_pgd = sum([model(pgd_images) for model in ensemble_model_set]) / len(ensemble_model_set)\n",
        "\n",
        "          # Calculate distillation loss\n",
        "          outputs = student_model(images)\n",
        "          loss = distillation_loss(outputs, labels, ensemble_outputs, T, alpha_distillation)\n",
        "\n",
        "          outputs_fgsm = student_model(fgsm_images)\n",
        "          loss_fgsm = distillation_loss(outputs_fgsm, labels, ensemble_outputs_fgsm, T, alpha_distillation)\n",
        "\n",
        "          outputs_pgd = student_model(pgd_images)\n",
        "          loss_pgd = distillation_loss(outputs_pgd, labels, ensemble_outputs_pgd, T, alpha_distillation)\n",
        "\n",
        "          # Combine all three losses\n",
        "          total_loss = loss + loss_fgsm + loss_pgd\n",
        "          total_loss.backward()\n",
        "          optimizer_student_model.step()\n",
        "\n",
        "          running_loss += total_loss.item()\n",
        "          _, predicted = outputs.max(1)\n",
        "          total += labels.size(0)\n",
        "          correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "          if batch_idx % 100 == 0:\n",
        "           print('Train Epoch: {} [{}]\\tLoss: {:.6f}\\tAccuracy: {:.6f}%'.format(\n",
        "               epoch + 1, batch_idx, loss.item(), 100.*correct/total))\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}, Accuracy: {100.*correct/total:.2f}%')\n",
        "\n",
        "    # Validation phase\n",
        "    student_model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (ids, images, labels) in enumerate(val_loader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = student_model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            val_total += labels.size(0)\n",
        "            val_correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    val_accuracy = 100. * val_correct / val_total\n",
        "    print(f'Validation Loss: {val_loss/len(val_loader):.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
        "\n",
        "torch.save(student_model.state_dict(), 'robust_student_model10.pt')"
      ],
      "metadata": {
        "id": "1cFtk1NfcG_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following block helps to obtain the clean as well as adversarial accuracy against FGSM and PGD on the validation dataset."
      ],
      "metadata": {
        "id": "aPEtWapNkJi_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVVBxGvTQ5Q0"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, loader, attack=None, epsilon=None):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (ids, images, labels) in enumerate(loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        if attack:\n",
        "            images = attack(model, images, labels, epsilon)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy\n",
        "\n",
        "clean_accuracy = evaluate(student_model, val_loader)\n",
        "fgsm_accuracy = evaluate(student_model, val_loader, fgsm_attack, epsilon=0.050)\n",
        "pgd_accuracy = evaluate(student_model, val_loader, pgd_attack, epsilon=0.050)\n",
        "\n",
        "print(f'Clean accuracy: {clean_accuracy:.2f}%')\n",
        "print(f'FGSM accuracy: {fgsm_accuracy:.2f}%')\n",
        "print(f'PGD accuracy: {pgd_accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Submission of the model and obtaining clean and adversarial accuracy on evaluation dataset"
      ],
      "metadata": {
        "id": "YW-pw9HskaCu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X030kLveYEy8"
      },
      "outputs": [],
      "source": [
        "#### Tests ####\n",
        "# (these are being ran on the eval endpoint for every submission)\n",
        "\n",
        "allowed_models = {\n",
        "    \"resnet18\": models.resnet18,\n",
        "    \"resnet34\": models.resnet34,\n",
        "    \"resnet50\": models.resnet50,\n",
        "}\n",
        "with open(\"./robust_student_model10.pt\", \"rb\") as f:\n",
        "    try:\n",
        "        model: torch.nn.Module = allowed_models[\"resnet50\"](weights=None)\n",
        "        model.fc = torch.nn.Linear(model.fc.weight.shape[1], 10)\n",
        "    except Exception as e:\n",
        "        raise Exception(\n",
        "            f\"Invalid model class, {e=}, only {allowed_models.keys()} are allowed\",\n",
        "        )\n",
        "    try:\n",
        "        state_dict = torch.load(f, map_location=torch.device(\"cpu\"))\n",
        "        model.load_state_dict(state_dict, strict=True)\n",
        "        model.eval()\n",
        "        out = model(torch.randn(1, 3, 32, 32))\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"Invalid model, {e=}\")\n",
        "\n",
        "    assert out.shape == (1, 10), \"Invalid output shape\"\n",
        "\n",
        "\n",
        "# Send the model to the server\n",
        "response = requests.post(\"http://34.71.138.79:9090/robustness\", files={\"file\": open(\"./robust_student_model10.pt\", \"rb\")}, headers={\"token\": \"92593601\", \"model-name\": \"resnet50\"})\n",
        "\n",
        "# Should be 400, the clean accuracy is too low\n",
        "print(response.json())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}