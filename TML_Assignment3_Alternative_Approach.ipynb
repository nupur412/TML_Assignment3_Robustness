{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is an alternative approach to train a robust classifier against adversarial examples and implement an approach that achieves the high accuracy for clean, as well as adversarial examples created using FGSM and PGD based on Assignment 3 of course on Trustworthy Machine Learning offered during Summer Semester 2024."
      ],
      "metadata": {
        "id": "bypDsefK_XU6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6Hme9C3E4bm"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "from torchvision import models\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torchvision.models import resnet18, resnet34, resnet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RU5x2DvNIz2",
        "outputId": "54aa607d-9d68-4416-dc5f-bea3d9fa8bbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xm4NfdKNNU0"
      },
      "outputs": [],
      "source": [
        "os.chdir(\"/content/drive/MyDrive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDethSapFaJN"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SL5sdGfALvIb",
        "outputId": "9020e231-04b1-4114-aff2-ee2b47120e4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cwd:  /content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import json\n",
        "import io\n",
        "import sys\n",
        "import base64\n",
        "from torch.utils.data import Dataset\n",
        "from typing import Tuple\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "cwd = os.getcwd()\n",
        "print('cwd: ', cwd)\n",
        "\n",
        "class TaskDataset(Dataset):\n",
        "    def __init__(self, transform=None):\n",
        "\n",
        "        self.ids = []\n",
        "        self.imgs = []\n",
        "        self.labels = []\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index) -> Tuple[int, torch.Tensor, int]:\n",
        "        id_ = self.ids[index]\n",
        "        img = self.imgs[index]\n",
        "        if not self.transform is None:\n",
        "            img = self.transform(img)\n",
        "        label = self.labels[index]\n",
        "        return id_, img, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the dataset and applying transformation"
      ],
      "metadata": {
        "id": "GU7DGVsAEISZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKNNCWgWNaJF"
      },
      "outputs": [],
      "source": [
        "data: TaskDataset = torch.load(\"./Train.pt\", map_location=\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFlfSN7CFyCa"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.Lambda(lambda x: x.convert(\"RGB\")),\n",
        "        transforms.ToTensor(),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Dg9kihMF6sj"
      },
      "outputs": [],
      "source": [
        "data.transform = transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rKd6f_73AsA"
      },
      "outputs": [],
      "source": [
        "# The length of the provided dataset is 100000, so we split it into train and validation datasets\n",
        "train_size = 90000\n",
        "val_size = 10000\n",
        "\n",
        "# Split the dataset\n",
        "train_dataset, val_dataset = random_split(data, [train_size, val_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJN6wvqsGxV6"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following block, we define the TRADES loss function referred from these experiments - [Tradeoff-inspired Adversarial Defense via Surrogate-loss minimization](https://github.com/yaodongyu/TRADES)"
      ],
      "metadata": {
        "id": "myvFikZLmmDW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqRXBR_6OKNl"
      },
      "outputs": [],
      "source": [
        "def trades_loss(model, x_natural, y, optimizer, step_size=0.007, epsilon=0.050, perturb_steps=15, beta=6.0):\n",
        "    model.eval()\n",
        "    batch_size = len(x_natural)\n",
        "    x_adv = x_natural.detach() + 0.001 * torch.randn(x_natural.shape).to(device).detach()\n",
        "\n",
        "    for _ in range(perturb_steps):\n",
        "        x_adv.requires_grad_()\n",
        "        with torch.enable_grad():\n",
        "            logits_adv = model(x_adv)\n",
        "            logits_natural = model(x_natural)\n",
        "            loss_kl = F.kl_div(F.log_softmax(model(x_adv), dim=1),\n",
        "                               F.softmax(model(x_natural), dim=1),\n",
        "                               reduction='batchmean')\n",
        "\n",
        "        grad = torch.autograd.grad(loss_kl, [x_adv])[0]\n",
        "        grad = torch.clamp(grad, min=-1, max=1)\n",
        "        x_adv = x_adv.detach() + step_size * torch.sign(grad.detach())\n",
        "        x_adv = torch.min(torch.max(x_adv, x_natural - epsilon), x_natural + epsilon)\n",
        "        x_adv = torch.clamp(x_adv, 0.0, 1.0)\n",
        "\n",
        "    model.train()\n",
        "    x_adv = x_adv.detach()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(x_natural)\n",
        "    loss_natural = F.cross_entropy(logits, y)\n",
        "    loss_robust = (1.0 / batch_size) * F.kl_div(F.log_softmax(model(x_adv), dim=1),\n",
        "                                                F.softmax(model(x_natural), dim=1),\n",
        "                                                reduction='batchmean')\n",
        "    loss = loss_natural + beta * loss_robust\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining a pretrained Resnet50 model"
      ],
      "metadata": {
        "id": "bSNNr3bIpThB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_3DS8U7N4lb"
      },
      "outputs": [],
      "source": [
        "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "\n",
        "state_dict_path = './submission.pt'\n",
        "state_dict = torch.load(state_dict_path, map_location=torch.device('cpu'))\n",
        "\n",
        "# Step 5: Apply the state dictionary to the model\n",
        "model.load_state_dict(state_dict)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvmIMMMIOfTa"
      },
      "outputs": [],
      "source": [
        "# Set the optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 75], gamma=0.1)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "learning_rate = 0.1\n",
        "num_epochs = 150\n",
        "epsilon = 0.031\n",
        "alpha = 0.007\n",
        "perturb_steps = 10\n",
        "beta = 6.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vq6EUrwJGhdS"
      },
      "outputs": [],
      "source": [
        "for epoch in range(100):\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  train_loss = 0.0\n",
        "  for batch_idx, (ids, images, labels) in enumerate(train_loader):\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      loss = trades_loss(model, images, labels, optimizer)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      train_loss += loss.item()\n",
        "\n",
        "      # Calculate accuracy\n",
        "      _, predicted = model(images).max(1)\n",
        "      total += labels.size(0)\n",
        "      correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "      # Batchwise accuracy and loss\n",
        "      if batch_idx % 10 == 0:\n",
        "            print('Train Epoch: {} [{}]\\tLoss: {:.6f}\\tAccuracy: {:.6f}%'.format(\n",
        "                epoch + 1, batch_idx, loss.item(), 100.*correct/total))\n",
        "  scheduler.step()\n",
        "  # Epoch accuracy and loss\n",
        "  print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss/len(train_loader)}, Accuracy: {100.*correct/total:.2f}%')\n",
        "\n",
        "  # Validation phase\n",
        "  model.eval()\n",
        "  val_loss = 0.0\n",
        "  val_correct = 0\n",
        "  val_total = 0\n",
        "  with torch.no_grad():\n",
        "      for batch_idx, (ids, images, labels) in enumerate(val_loader):\n",
        "          images, labels = images.to(device), labels.to(device)\n",
        "          outputs = model(images)\n",
        "          loss = criterion(outputs, labels)\n",
        "\n",
        "          val_loss += loss.item()\n",
        "          _, predicted = outputs.max(1)\n",
        "          val_total += labels.size(0)\n",
        "          val_correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "  val_accuracy = 100. * val_correct / val_total\n",
        "  print(f'Validation Loss: {val_loss/len(val_loader):.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
        "\n",
        "torch.save(model.state_dict(), \"submission.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vppn8NQYnXdu"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"submission_new2.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVVBxGvTQ5Q0",
        "outputId": "fe6e798b-5171-4042-f53f-7d62d39b4371"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clean accuracy: 96.25%\n"
          ]
        }
      ],
      "source": [
        "def evaluate_model(model, loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (ids, images, labels) in enumerate(loader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "clean_accuracy = evaluate_model(model, val_loader)\n",
        "print(f'Clean accuracy: {clean_accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZJWQ4Ydos8N"
      },
      "outputs": [],
      "source": [
        "def pgd_attack(model, images, labels, eps=0.031, alpha=0.007, iters=10):\n",
        "    images = images.clone().detach().to(device)\n",
        "    labels = labels.clone().detach().to(device)\n",
        "    original_images = images.clone().detach()\n",
        "\n",
        "    for i in range(iters):\n",
        "        images.requires_grad = True\n",
        "        outputs = model(images)\n",
        "        model.zero_grad()\n",
        "        cost = criterion(outputs, labels).to(device)\n",
        "        cost.backward()\n",
        "\n",
        "        adv_images = images + alpha * images.grad.sign()\n",
        "        eta = torch.clamp(adv_images - original_images, min=-eps, max=eps)\n",
        "        images = torch.clamp(original_images + eta, min=0, max=1).detach_()\n",
        "\n",
        "    return images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zoD86Unnn6tj"
      },
      "outputs": [],
      "source": [
        "def fgsm_attack(image, epsilon, data_grad):\n",
        "    # Collect the sign of the gradients of the input\n",
        "    sign_data_grad = data_grad.sign()\n",
        "    # Create the perturbed image by adjusting each pixel of the input image\n",
        "    perturbed_image = image + epsilon * sign_data_grad\n",
        "    # Adding clipping to maintain [0,1] range\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    return perturbed_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdlbxqyJeUm6",
        "outputId": "f43ac44a-7eac-4fd1-ce83-d8ce740d7584"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FGSM accuracy: 42.18%\n"
          ]
        }
      ],
      "source": [
        "# Calculate FGSM accuracy\n",
        "def evaluate_fgsm(model, loader, epsilon):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (ids, images, labels) in enumerate(loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        images.requires_grad = True\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        data_grad = images.grad.data\n",
        "        perturbed_data = fgsm_attack(images, epsilon, data_grad)\n",
        "\n",
        "        outputs = model(perturbed_data)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "fgsm_accuracy = evaluate_fgsm(model, val_loader, epsilon=0.031)\n",
        "print(f'FGSM accuracy: {fgsm_accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LelvKrcIecAN",
        "outputId": "d9c82059-a1d4-4276-d55f-def417c05903"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD accuracy: 13.39%\n"
          ]
        }
      ],
      "source": [
        "# Calculate PGD accuracy\n",
        "def evaluate_pgd(model, loader, epsilon, alpha, iters):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (ids, images, labels) in enumerate(loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        adv_images = pgd_attack(model, images, labels, epsilon, alpha, iters)\n",
        "        outputs = model(adv_images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "pgd_accuracy = evaluate_pgd(model, val_loader, epsilon=0.031, alpha=0.007, iters=10)\n",
        "print(f'PGD accuracy: {pgd_accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X030kLveYEy8",
        "outputId": "490f0a80-7e86-4c7f-ae61-9c066b15c448"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'clean_accuracy': 0.598, 'fgsm_accuracy': 0.298, 'pgd_accuracy': 0.07166666666666667}\n"
          ]
        }
      ],
      "source": [
        "# torch.save(model.state_dict(), \"submission.pt\")\n",
        "\n",
        "#### Tests ####\n",
        "# (these are being ran on the eval endpoint for every submission)\n",
        "\n",
        "allowed_models = {\n",
        "    \"resnet18\": models.resnet18,\n",
        "    \"resnet34\": models.resnet34,\n",
        "    \"resnet50\": models.resnet50,\n",
        "}\n",
        "with open(\"./submission.pt\", \"rb\") as f:\n",
        "    try:\n",
        "        model: torch.nn.Module = allowed_models[\"resnet50\"](weights=None)\n",
        "        model.fc = torch.nn.Linear(model.fc.weight.shape[1], 10)\n",
        "        # replace_relu_with_silu(model)\n",
        "    except Exception as e:\n",
        "        raise Exception(\n",
        "            f\"Invalid model class, {e=}, only {allowed_models.keys()} are allowed\",\n",
        "        )\n",
        "    try:\n",
        "        state_dict = torch.load(f, map_location=torch.device(\"cpu\"))\n",
        "        model.load_state_dict(state_dict, strict=True)\n",
        "        model.eval()\n",
        "        out = model(torch.randn(1, 3, 32, 32))\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"Invalid model, {e=}\")\n",
        "\n",
        "    assert out.shape == (1, 10), \"Invalid output shape\"\n",
        "\n",
        "\n",
        "# Send the model to the server\n",
        "response = requests.post(\"http://34.71.138.79:9090/robustness\", files={\"file\": open(\"./submission.pt\", \"rb\")}, headers={\"token\": \"92593601\", \"model-name\": \"resnet50\"})\n",
        "\n",
        "# Should be 400, the clean accuracy is too low\n",
        "print(response.json())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
